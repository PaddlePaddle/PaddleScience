# Transolver: A Fast Transformer Solver for PDEs on General Geometries(Transolver：一种在一般几何形状上快速求解偏微分方程的Transformer求解器)

Distributed under a creative commons Attribution license 4.0 (CC BY). 

## 1. 背景简介
### 1.1 论文信息:

|年份 | 期刊 | 作者|引用数 | 论文PDF | 
|-----|-----|-----|---|-----|
|October 2024|ICML Spotlight|Haixu Wu, Huakun Luo, Haowen Wang, Jianmin Wang, Mingsheng Long|15|[Paper](https://dataset.bj.bcebos.com/PaddleScience/2024%20Transolver/2402.02366v2.pdf)|

### 1.2 作者介绍

#### 第一作者：清华大学 软件学院 Haixu Wu (Cited 5499)

个人主页：https://wuhaixu2016.github.io/

研究方向：深度学习和科学机器学习，序列建模、物理世界建模、PDE 求解

![alt text](https://dataset.bj.bcebos.com/PaddleScience/2024%20Transolver/transolver_1.png)

#### 通讯作者：清华大学 软件学院 Mingsheng Long (Cited 42149)

教师主页：https://ise.thss.tsinghua.edu.cn/~mlong/

研究方向：深度学习、迁移学习、科学机器学习、地球模型、神经求解器、时间序列、时空动态

![alt text](https://dataset.bj.bcebos.com/PaddleScience/2024%20Transolver/transolver_1.png)


### 1.3 模型&复现代码

|问题类型 | 在线运行 |神经网络|预训练模型|指标|
|---------|-----|---------|-|-|
|算子神经网络预测流场|[AI Studio 一键运行](https://aistudio.baidu.com/projectdetail/8252779?sUid=1952564&shared=1&ts=172724369783)|Transformer几何神经算子|[GeoFNO_pretrained.pdparams](https://paddle-org.bj.bcebos.com/paddlescience/models/GeoFNO/GeoFNO_pretrained.pdparams)|loss(MAE): 0.4195|


Transformer模型已在多个领域取得了众多里程碑式的成就，并且最近被应用于求解偏微分方程（PDEs）。然而，由于PDEs通常被离散化为具有复杂几何形状的大规模网格，Transformer模型直接从海量的独立点中捕捉精细的物理相关性面临挑战。为了超越表面化和笨拙的网格表示，我们提出了一种基于更基础理念的Transolver，即学习隐藏在离散化几何形状背后的内在物理状态。

具体来说，我们提出了一种新的PhysicsAttention机制，它能够自适应地将离散化的域划分为一系列可学习的、形状灵活的切片，其中处于相似物理状态的网格点将被归入同一个切片中。通过计算对从切片中编码的物理感知标记（tokens）的注意力，Transolver能够有效地捕捉复杂几何形状下的精细物理相关性。这不仅赋予了求解器内生的几何泛化建模能力，而且能够以线性复杂度高效地进行计算。

Transolver在六个标准基准测试上取得了持续领先的性能，相对增益达到22%，并且在包括汽车和翼型设计在内的大规模工业模拟中也表现出色。


### 1.3.1 介绍
求解偏微分方程（PDEs）在广泛的现实世界应用中具有极其重要的意义，如天气预报、工业设计和材料分析（Roub ́íček, 2013）。作为一个基础科学问题，PDEs通常很难获得解析解。因此，在实践中，PDEs通常被离散化为网格，然后通过数值方法求解，对于复杂结构，这通常需要几个小时甚至几天的时间（Umetani & Bickel, 2018）。

近年来，深度模型已成为求解PDEs的有前途的工具（Lu et al., 2021; Li et al., 2021）。得益于其令人印象深刻的非线性建模能力，它们可以在训练期间从数据中学习PDE控制任务的输入和输出映射，然后在推理阶段以比数值方法快得多的速度推断出解决方案（Goswami et al., 2022; Wu et al., 2023）。

作为基础模型的主要支柱，Transformer（Vaswani et al., 2017）在广泛领域取得了显著进展（Devlin et al., 2019; Brown et al., 2020; Dosovitskiy et al., 2021; Liu et al., 2021），并且也已被引入PDE求解中（Li et al., 2023c）。然而，由于PDEs通常被离散化为具有复杂几何形状的大规模网格以进行精确模拟，直接将Transformer应用于大量网格点在计算效率和关系学习方面都面临困难（Liu et al., 2021; Katharopoulos et al., 2020b），这阻碍了它们成为理想的PDE求解器。例如，为了计算行驶汽车的阻力（图1），模型需要近似Navier-Stokes方程的解，包括估计表面网格的压力和周围体积的速度，这带来了以下两个挑战。首先，这个问题涉及数万个不规则放置的网格点的协作建模，由于其二次复杂度，标准注意力在计算上是禁止的。其次，PDEs涉及多个物理量之间极其复杂的时空相互作用。很难直接从大量单个点中捕捉这些高阶和复杂的相关性。因此，如何有效地捕捉离散化域中潜在的物理相关性是将Transformer“转变”为实用PDE求解器的关键。

以前的方法尝试通过引入线性注意力（Hao et al., 2023; Tran et al., 2023）来解决复杂性问题，但直接将注意力应用于大量网格点可能会使模型无法学习有信息的关系（Wu et al., 2022）。此外，仅依赖单个点的特征也不足以捕捉PDEs的复杂物理相关性（Trockman & Kolter, 2022），尤其是对于通常涉及极其复杂的多物理场相互作用的工业设计而言。此外，尽管在Vision Transformer（Dosovitskiy et al., 2021; Liu et al., 2021）中广泛采用patchify操作来用局部信息增强单个像素的特征，但patch的规则形状不适用于非结构化几何形状，更不用说捕捉隐藏在各种离散化网格下的复杂物理状态了。

透过表面和笨拙的网格，本文提出了一种基于更基础理念的Transolver，即学习复杂几何形状下的内在物理状态。我们提出了Physics-Attention来将离散化域分解为一系列可学习的切片，其中处于相似物理状态的网格点将被归入同一个切片，然后编码为物理感知标记（token）。通过对这些学习的物理感知标记应用注意力，Physics-Attention可以有效地捕捉离散化域背后复杂的潜在相互作用。如图1所示，学习的切片清晰地反映了PDEs的各种物理状态，如Darcy流中的各种流固相互作用、弹性材料的不同挤压区域、翼型周围的冲击波和尾流、行驶汽车的前后表面和上下空间。这种设计还可以自然地适应复杂的几何形状，并在线性时间内有效计算。

![图1. Transolver中学习到的切片可视化](https://dataset.bj.bcebos.com/PaddleScience/2024%20Transolver/transolver_3.png)

图1. Transolver中学习到的切片可视化。对于每个案例，最左侧的子图是模型输入，右侧显示的是学习到的切片。颜色越亮表示网格点越归属于对应的切片。更多可视化内容请参见附录D。


我们在六个具有各种几何形状的大型工业模拟基准上进行了广泛的实验，其中Transolver取得了始终如一的最先进性能，并获得了令人印象深刻的相对增益。总的来说，我们的贡献总结如下：

• 我们提出了一种超越以往方法的新途径来解决偏微分方程（PDEs），即通过学习离散化域背后的内在物理状态，从而使我们的模型摆脱复杂网格的束缚，能够更加专注于物理交互。

• 我们推出了带有物理注意力机制的Transolver，该方法将离散化域分解为一系列可学习的切片，并对编码后的物理感知标记（tokens）应用注意力机制，这种计算方式具有线性复杂度。

• Transolver在六个标准基准测试中取得了持续领先的状态，相对增益达到22%，并且在大型工业模拟（如汽车和翼型设计）中表现出色，展现了良好的效率、可扩展性和对未知分布的泛化能力。


表2. 标准基准测试上的性能比较。记录的是相对L2误差。数值越小表示性能越好。为清晰起见，最佳结果用粗体表示，次佳结果用下划线标记。提升率（Promotion）指的是相对于次佳模型在每个基准测试上的相对误差减少率（$(1-\frac{\mathrm{Our~error}}{\text{The second best error}})$）。“/”表示基线模型不适用于此基准测试。
| 模型名称                   | 弹性 （点云）      | 塑性(结构化网格)       | Airfrans机翼     | 管道       | Navier-Stokes | Darcy   |
|---------------------------|----------|----------|----------|----------|--------------|---------|
| FNO (LI ET AL., 2021)     | /          | /          | /          | /          | 0.1556       | 0.0108  |
| WMT (GUPTA ET AL., 2021)  | 0.0359     | 0.0076     | 0.0075     | 0.0077     | 0.1541       | 0.0082  |
| U-FNO (WEN ET AL., 2022)  | 0.0239     | 0.0039     | 0.0269     | 0.0056     | 0.2231       | 0.0183  |
| GEO-FNO (LI ET AL., 2022) | 0.0229     | 0.0074     | 0.0138     | 0.0067     | 0.1556       | 0.0108  |
| U-NO (RAHMAN ET AL., 2023)| 0.0258     | 0.0034     | 0.0078     | 0.0100     | 0.1713       | 0.0113  |
| F-FNO (TRAN ET AL., 2023) | 0.0263     | 0.0047     | 0.0078     | 0.0070     | 0.2322       | 0.0077  |
| LSM (WU ET AL., 2023)     | 0.0263     | 0.0025     | <u>0.0059</u>  | 0.0050 | 0.1535       | <u>0.0065</u>   |
| GALERKIN (CAO, 2021)      | 0.0240     | 0.0120     | 0.0118     | 0.0098     | 0.1401           | 0.0084     |
| HT-NET (LIU ET AL., 2022) | /          | 0.0333     | 0.0065     | 0.0059     | 0.1847       | 0.0079       |
| OFORMER (LI ET AL., 2023C)| 0.0183     | <u>0.0017</u>      | 0.0183     | 0.0168         | 0.1705            |0.0124       |
| GNOT (HAO ET AL., 2023)   | <u>0.0086</u>     | 0.0336     | 0.0076     | <u>0.0047</u>     | 0.1380   | 0.0105|
| FACTFORMER (LI ET AL., 2023D)| /       | 0.0312     | 0.0071     | 0.0060     | 0.1214       | 0.0109  |
| ONO (XIAO ET AL., 2024)  | 0.0118      | 0.0048     | 0.0061     | 0.0052     | <u>0.1195</u>       | 0.0076  |
| **TRANSOLVER (OURS)**    | **0.0064**  | **0.0012** | **0.0053** | **0.0033** | **0.0900**   | **0.0057** |
|RELATIVE PROMOTION|25.6%|29.4%|10.2%|29.7%|24.7%|12.3%|
|